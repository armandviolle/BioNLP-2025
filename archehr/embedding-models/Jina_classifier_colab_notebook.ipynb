{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[q] [SEP] [sent1 + sent2 + sent3 + ... + sentn]"
      ],
      "metadata": {
        "id": "4_KIA7Bh2mOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "id": "1iHyCbQONiJ4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the dependencies\n",
        "\n",
        "*Hardware : GPU A100 on Google colab pro*"
      ],
      "metadata": {
        "id": "r2tv7MTuYReQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet torch==2.2.2+cu121 torchvision==0.17.2+cu121 torchaudio==2.2.2+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install --quiet --upgrade transformers sentence-transformers\n",
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "339GH-Ep3XI_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja packaging\n",
        "!MAX_JOBS=8 pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "B9hSjtov7TmE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Torch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVnp1Hjs0RrJ",
        "outputId": "3138e04d-67ce-481e-f1f6-fdad485137aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.2.2+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the augmented dataset"
      ],
      "metadata": {
        "id": "MNuaYZn0YvW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#Load the augmented dataset\n",
        "df = pd.read_excel(\"'/content/gdrive/MyDrive/dataset_excel_bionlp/final_dataset/qa_train_dataset_structured_05-05.xlsx'\")"
      ],
      "metadata": {
        "id": "mrFwcTQfYinb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Preview\n",
        "# df"
      ],
      "metadata": {
        "id": "kwlVJRiAEiqI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Number of rows:\", len(df))"
      ],
      "metadata": {
        "id": "cs1u5BopfUAe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning"
      ],
      "metadata": {
        "id": "jh9vWZ0bDbdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using just train (no validation)"
      ],
      "metadata": {
        "id": "A969uTep4ZFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG\n",
        "# -----------------------\n",
        "\n",
        "MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 1\n",
        "EPOCHS = 6\n",
        "\n",
        "# -----------------------\n",
        "# DATA LOADING\n",
        "# -----------------------\n",
        "# df = pd.read_excel(\"/content/gdrive/MyDrive/dataset_excel_bionlp/final_dataset/qa_results_structured_03-05.xlsx\")\n",
        "df[\"binary_relevance\"] = df[\"relevance\"].apply(lambda x: 1 if x.strip().lower() == \"essential\" else 0)\n",
        "\n",
        "# Group by case\n",
        "grouped_data = []\n",
        "for case_id, group in df.groupby(\"case_id\"):\n",
        "    question = group[\"question_generated\"].iloc[0]\n",
        "    sentences = group[\"ref_excerpt\"].tolist()\n",
        "    labels = group[\"binary_relevance\"].tolist()\n",
        "    grouped_data.append({\n",
        "        \"question\": question,\n",
        "        \"sentences\": [s.strip() for s in sentences],\n",
        "        \"labels\": labels\n",
        "    })\n",
        "\n",
        "# -----------------------\n",
        "# DATASET\n",
        "# -----------------------\n",
        "class SentenceClassificationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=512):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        question = item[\"question\"]\n",
        "        sentences = item[\"sentences\"]\n",
        "        labels = item[\"labels\"]\n",
        "\n",
        "\n",
        "        separator = \"</s>\"\n",
        "        text = question + f\" {separator} \" + f\" {separator} \".join(sentences)\n",
        "\n",
        "\n",
        "\n",
        "        # ðŸ” Check token count before truncation\n",
        "        tokens_total = len(self.tokenizer.tokenize(text))\n",
        "        if tokens_total > self.max_length:\n",
        "            print(f\"[!] Truncated from {tokens_total} â†’ {self.max_length} tokens\")\n",
        "\n",
        "\n",
        "        encoding = self.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"][0]\n",
        "        sent_token_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
        "        sep_positions = (input_ids == sent_token_id).nonzero(as_tuple=True)[0]\n",
        "\n",
        "\n",
        "        # sep_positions = (input_ids == sep_token_id).nonzero(as_tuple=True)[0][1:]\n",
        "\n",
        "        # If no [SEP] tokens are found (after question), fallback\n",
        "        if len(sep_positions) == 0:\n",
        "            # Insert dummy [SEP] and dummy label\n",
        "            sep_positions = torch.tensor([1])\n",
        "            labels = [0]\n",
        "\n",
        "        # Also truncate labels to match sep_positions\n",
        "        labels = labels[:len(sep_positions)]\n",
        "        # DEBUG PRINT (only for a few examples)\n",
        "        # if idx < 3:  # Only print for first 3 batches\n",
        "        #     print(f\"\\nExample {idx}\")\n",
        "        #     print(f\"Question: {question}\")\n",
        "        #     print(f\"Sentences: {sentences}\")\n",
        "        #     print(f\"Labels: {labels}\")\n",
        "        #     print(f\"Number of SEP positions found: {len(sep_positions)}\")\n",
        "        #     print(f\"Input IDs shape: {input_ids.shape}\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": encoding[\"attention_mask\"][0],\n",
        "            \"sep_positions\": sep_positions,\n",
        "            \"labels\": torch.tensor(labels)\n",
        "        }\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# MODEL WRAPPER\n",
        "# -----------------------\n",
        "class MultiSentenceClassifier(nn.Module):\n",
        "    def __init__(self, base_model_name):\n",
        "        super().__init__()\n",
        "        self.encoder = SentenceTransformer(\n",
        "            base_model_name,\n",
        "            trust_remote_code=True,\n",
        "            model_kwargs={\"default_task\": \"classification\",\"lora_main_params_trainable\": True})\n",
        "        self.encoder[0].default_task = \"classification\"\n",
        "        #self.encoder = self.encoder.float()\n",
        "        hidden_size = self.encoder.get_sentence_embedding_dimension()\n",
        "        self.classifier = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, sep_positions):\n",
        "        output = self.encoder[0].auto_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        token_embeddings = output.last_hidden_state\n",
        "\n",
        "        preds = []\n",
        "        for i in range(input_ids.shape[0]):\n",
        "            sep_pos = sep_positions[i]\n",
        "            if len(sep_pos) == 0:\n",
        "                continue  # skip if somehow empty\n",
        "            sentence_embs = token_embeddings[i, sep_pos, :].float()\n",
        "            logits = self.classifier(sentence_embs).squeeze(-1)\n",
        "            preds.append(logits)\n",
        "\n",
        "        return preds\n",
        "\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.75, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        probs = torch.sigmoid(inputs)\n",
        "        alpha_factor = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n",
        "        focal_weight = (targets * (1 - probs) + (1 - targets) * probs) ** self.gamma\n",
        "        loss = alpha_factor * focal_weight * BCE_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        else:\n",
        "            return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# TRAINING\n",
        "# -----------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "\n",
        "model = MultiSentenceClassifier(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "\n",
        "dataset = SentenceClassificationDataset(grouped_data, tokenizer, max_length=4096)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "\n",
        "\n",
        "pos = df[\"binary_relevance\"].value_counts()[1]\n",
        "neg = df[\"binary_relevance\"].value_counts()[0]\n",
        "pos_weight_value = (neg / pos)\n",
        "\n",
        "\n",
        "pos_weight = torch.tensor([pos_weight_value], device=DEVICE)\n",
        "\n",
        "print(\"Using pos weight value:\", pos_weight_value)\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "\n",
        "# criterion = FocalLoss(alpha=0.65, gamma=2)\n",
        "\n",
        "\n",
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        sep_positions = [x.to(DEVICE) for x in batch[\"sep_positions\"]]\n",
        "        labels = [x.to(DEVICE).float() for x in batch[\"labels\"]]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
        "            outputs = model(input_ids, attention_mask, sep_positions)\n",
        "\n",
        "            sample_losses = []\n",
        "\n",
        "            for pred, target in zip(outputs, labels):\n",
        "                if pred.numel() == 0 or target.numel() == 0:\n",
        "                    continue\n",
        "                if pred.shape != target.shape:\n",
        "                    min_len = min(pred.shape[0], target.shape[0])\n",
        "                    pred = pred[:min_len]\n",
        "                    target = target[:min_len]\n",
        "                sample_losses.append(criterion(pred, target))\n",
        "\n",
        "\n",
        "            if sample_losses:\n",
        "                loss = torch.stack(sample_losses).mean()\n",
        "            else:\n",
        "                continue  # skip if nothing valid\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:  # replace with val_dataloader when ready\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            sep_positions = [x.to(DEVICE) for x in batch[\"sep_positions\"]]\n",
        "            labels = [x.to(DEVICE).float() for x in batch[\"labels\"]]\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, sep_positions)\n",
        "\n",
        "            for pred, target in zip(outputs, labels):\n",
        "                if pred.numel() == 0 or target.numel() == 0:\n",
        "                    continue\n",
        "                if pred.shape != target.shape:\n",
        "                    min_len = min(pred.shape[0], target.shape[0])\n",
        "                    pred = pred[:min_len]\n",
        "                    target = target[:min_len]\n",
        "\n",
        "                probs = torch.sigmoid(pred).cpu().numpy()\n",
        "                binarized = (probs > 0.5).astype(int)\n",
        "\n",
        "                all_preds.extend(binarized.tolist())\n",
        "                all_targets.extend(target.cpu().numpy().tolist())\n",
        "\n",
        "    print(\"\\nEvaluation Metrics:\")\n",
        "    print(classification_report(all_targets, all_preds, digits=3))\n",
        "    model.train()\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# SAVE\n",
        "# -----------------------\n",
        "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/qlora_outputs/fine_tuned_jina_v3_multisent.pt\")\n"
      ],
      "metadata": {
        "id": "x9wZO-ErNiMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use train, validation split\n"
      ],
      "metadata": {
        "id": "tA-Yt0t34PbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# import pandas as pd\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from transformers import AutoTokenizer\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import numpy as np\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# # -----------------------\n",
        "# # CONFIG\n",
        "# # -----------------------\n",
        "# MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# BATCH_SIZE = 1\n",
        "# EPOCHS = 6\n",
        "# PATIENCE = 2  # for early stopping\n",
        "\n",
        "# # -----------------------\n",
        "# # DATA LOADING\n",
        "# # -----------------------\n",
        "\n",
        "\n",
        "# df[\"binary_relevance\"] = df[\"relevance\"].apply(lambda x: 1 if x.strip().lower() == \"essential\" else 0)\n",
        "\n",
        "# grouped_data = []\n",
        "# for case_id, group in df.groupby(\"case_id\"):\n",
        "#     question = group[\"question_generated\"].iloc[0]\n",
        "#     sentences = group[\"ref_excerpt\"].tolist()\n",
        "#     labels = group[\"binary_relevance\"].tolist()\n",
        "#     grouped_data.append({\n",
        "#         \"question\": question,\n",
        "#         \"sentences\": [s.strip() for s in sentences],\n",
        "#         \"labels\": labels\n",
        "#     })\n",
        "\n",
        "# # -----------------------\n",
        "# # DATASET CLASS\n",
        "# # -----------------------\n",
        "# class SentenceClassificationDataset(Dataset):\n",
        "#     def __init__(self, data, tokenizer, max_length=512):\n",
        "#         self.data = data\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_length = max_length\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         item = self.data[idx]\n",
        "#         question = item[\"question\"]\n",
        "#         sentences = item[\"sentences\"]\n",
        "#         labels = item[\"labels\"]\n",
        "#         separator = \"</s>\"\n",
        "#         text = question + f\" {separator} \" + f\" {separator} \".join(sentences)\n",
        "\n",
        "#         encoding = self.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
        "#         input_ids = encoding[\"input_ids\"][0]\n",
        "#         sep_token_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
        "#         sep_positions = (input_ids == sep_token_id).nonzero(as_tuple=True)[0]\n",
        "\n",
        "#         if len(sep_positions) == 0:\n",
        "#             sep_positions = torch.tensor([1])\n",
        "#             labels = [0]\n",
        "\n",
        "#         labels = labels[:len(sep_positions)]\n",
        "\n",
        "#         return {\n",
        "#             \"input_ids\": input_ids,\n",
        "#             \"attention_mask\": encoding[\"attention_mask\"][0],\n",
        "#             \"sep_positions\": sep_positions,\n",
        "#             \"labels\": torch.tensor(labels)\n",
        "#         }\n",
        "\n",
        "# # -----------------------\n",
        "# # MODEL\n",
        "# # -----------------------\n",
        "# class MultiSentenceClassifier(nn.Module):\n",
        "#     def __init__(self, base_model_name):\n",
        "#         super().__init__()\n",
        "#         self.encoder = SentenceTransformer(\n",
        "#             base_model_name,\n",
        "#             trust_remote_code=True,\n",
        "#             model_kwargs={\"default_task\": \"classification\", \"lora_main_params_trainable\": True})\n",
        "#         self.encoder[0].default_task = \"classification\"\n",
        "#         hidden_size = self.encoder.get_sentence_embedding_dimension()\n",
        "#         self.classifier = nn.Linear(hidden_size, 1)\n",
        "\n",
        "#     def forward(self, input_ids, attention_mask, sep_positions):\n",
        "#         output = self.encoder[0].auto_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#         token_embeddings = output.last_hidden_state\n",
        "#         preds = []\n",
        "#         for i in range(input_ids.shape[0]):\n",
        "#             sep_pos = sep_positions[i]\n",
        "#             if len(sep_pos) == 0:\n",
        "#                 continue\n",
        "#             sentence_embs = token_embeddings[i, sep_pos, :].float()\n",
        "#             logits = self.classifier(sentence_embs).squeeze(-1)\n",
        "#             preds.append(logits)\n",
        "#         return preds\n",
        "\n",
        "\n",
        "# class FocalLoss(nn.Module):\n",
        "#     def __init__(self, alpha=0.75, gamma=2.0, reduction='mean'):\n",
        "#         super(FocalLoss, self).__init__()\n",
        "#         self.alpha = alpha\n",
        "#         self.gamma = gamma\n",
        "#         self.reduction = reduction\n",
        "\n",
        "#     def forward(self, inputs, targets):\n",
        "#         BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "#         probs = torch.sigmoid(inputs)\n",
        "#         alpha_factor = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n",
        "#         focal_weight = (targets * (1 - probs) + (1 - targets) * probs) ** self.gamma\n",
        "#         loss = alpha_factor * focal_weight * BCE_loss\n",
        "\n",
        "#         if self.reduction == 'mean':\n",
        "#             return loss.mean()\n",
        "#         elif self.reduction == 'sum':\n",
        "#             return loss.sum()\n",
        "#         else:\n",
        "#             return loss\n",
        "\n",
        "# # -----------------------\n",
        "# # TRAINING SETUP\n",
        "# # -----------------------\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "# model = MultiSentenceClassifier(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "# train_data, val_data = train_test_split(grouped_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# train_dataset = SentenceClassificationDataset(train_data, tokenizer, max_length=4096)\n",
        "# val_dataset = SentenceClassificationDataset(val_data, tokenizer, max_length=4096)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# pos = df[\"binary_relevance\"].value_counts()[1]\n",
        "# neg = df[\"binary_relevance\"].value_counts()[0]\n",
        "# # pos_weight_value = (neg / pos)\n",
        "# # pos_weight = torch.tensor([pos_weight_value], device=DEVICE)\n",
        "\n",
        "# # print(\"Using pos weight value:\", pos_weight_value)\n",
        "# # criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "# criterion = FocalLoss(alpha=0.75, gamma=2)\n",
        "\n",
        "# # -----------------------\n",
        "# # TRAINING LOOP W/ EARLY STOPPING\n",
        "# # -----------------------\n",
        "# best_f1 = 0.0\n",
        "# no_improve_epochs = 0\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "#     for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "#         input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "#         attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "#         sep_positions = [x.to(DEVICE) for x in batch[\"sep_positions\"]]\n",
        "#         labels = [x.to(DEVICE).float() for x in batch[\"labels\"]]\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
        "#             outputs = model(input_ids, attention_mask, sep_positions)\n",
        "#             sample_losses = []\n",
        "#             for pred, target in zip(outputs, labels):\n",
        "#                 if pred.numel() == 0 or target.numel() == 0:\n",
        "#                     continue\n",
        "#                 min_len = min(pred.shape[0], target.shape[0])\n",
        "#                 sample_losses.append(criterion(pred[:min_len], target[:min_len]))\n",
        "#             if sample_losses:\n",
        "#                 loss = torch.stack(sample_losses).mean()\n",
        "#             else:\n",
        "#                 continue\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     print(f\"Epoch {epoch + 1}/{EPOCHS} - Loss: {total_loss:.4f}\")\n",
        "\n",
        "#     # -----------------------\n",
        "#     # VALIDATION\n",
        "#     # -----------------------\n",
        "#     model.eval()\n",
        "#     all_preds, all_targets = [], []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for batch in val_loader:\n",
        "#             input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "#             attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "#             sep_positions = [x.to(DEVICE) for x in batch[\"sep_positions\"]]\n",
        "#             labels = [x.to(DEVICE).float() for x in batch[\"labels\"]]\n",
        "\n",
        "#             outputs = model(input_ids, attention_mask, sep_positions)\n",
        "\n",
        "#             for pred, target in zip(outputs, labels):\n",
        "#                 if pred.numel() == 0 or target.numel() == 0:\n",
        "#                     continue\n",
        "#                 min_len = min(pred.shape[0], target.shape[0])\n",
        "#                 probs = torch.sigmoid(pred[:min_len]).cpu().numpy()\n",
        "#                 binarized = (probs > 0.5).astype(int)\n",
        "#                 all_preds.extend(binarized.tolist())\n",
        "#                 all_targets.extend(target[:min_len].cpu().numpy().tolist())\n",
        "\n",
        "#     print(\"\\nValidation Metrics:\")\n",
        "#     report = classification_report(all_targets, all_preds, digits=3, output_dict=True)\n",
        "#     print(classification_report(all_targets, all_preds, digits=3))\n",
        "\n",
        "#     f1 = report.get(1.0, report.get('1.0', {})).get('f1-score', 0.0)\n",
        "#     if f1 > best_f1:\n",
        "#         best_f1 = f1\n",
        "#         no_improve_epochs = 0\n",
        "#         torch.save(model.state_dict(), \"/content/gdrive/MyDrive/qlora_outputs/best_model.pt\")\n",
        "#         print(\"New best model saved.\")\n",
        "#     else:\n",
        "#         no_improve_epochs += 1\n",
        "#         print(f\"No improvement for {no_improve_epochs} epoch(s)\")\n",
        "\n",
        "#     if no_improve_epochs >= PATIENCE:\n",
        "#         print(\"Early stopping triggered.\")\n",
        "#         break"
      ],
      "metadata": {
        "id": "6aSXQDZdN_FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "PJXeaepfDYo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-sViUko1z94",
        "outputId": "728f6d56-b74e-4b0e-d19a-989dee47ffe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the fine tuned model"
      ],
      "metadata": {
        "id": "YIHXEOfkXb2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Patient narrative"
      ],
      "metadata": {
        "id": "oUzO0QaKGjey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG\n",
        "# -----------------------\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/fine_tuned_jina_v3_multisent.pt\"\n",
        "# MODEL_PATH = \"/content/gdrive/MyDrive/qlora_outputs/fine_tuned_jina_v3_multisent.pt\"\n",
        "MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_LENGTH = 4096\n",
        "\n",
        "# -----------------------\n",
        "# LOAD TEST DATA\n",
        "# -----------------------\n",
        "df_test = pd.read_excel(\"/content/gdrive/MyDrive/dataset_excel_bionlp/merged_notes_cases.xlsx\")\n",
        "\n",
        "# question_column = 'clinician_question'\n",
        "question_column = 'patient_narrative'\n",
        "df_test = df_test.rename(columns={question_column: 'question_generated'})\n",
        "\n",
        "\n",
        "df_test[\"ref_excerpt\"] = df_test[\"ref_excerpt\"].astype(str)\n",
        "df_test[\"binary_relevance\"] = df_test[\"relevance\"].apply(lambda x: 1 if x.strip().lower() == \"essential\" else 0)\n",
        "\n",
        "grouped_data = []\n",
        "for case_id, group in df_test.groupby(\"case_id\"):\n",
        "    question = group[\"question_generated\"].iloc[0]\n",
        "    sentences = group[\"ref_excerpt\"].tolist()\n",
        "    labels = group[\"binary_relevance\"].tolist()\n",
        "    grouped_data.append({\n",
        "        \"question\": question,\n",
        "        \"sentences\": [s.strip() for s in sentences],\n",
        "        \"labels\": labels\n",
        "    })\n",
        "\n",
        "# -----------------------\n",
        "# TOKENIZER AND MODEL\n",
        "# -----------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "class MultiSentenceClassifier(torch.nn.Module):\n",
        "    def __init__(self, base_model_name):\n",
        "        super().__init__()\n",
        "        self.encoder = SentenceTransformer(\n",
        "            base_model_name,\n",
        "            trust_remote_code=True,\n",
        "            model_kwargs={\"default_task\": \"classification\", \"use_flash_attn\": True}\n",
        "        )\n",
        "        hidden_size = self.encoder.get_sentence_embedding_dimension()\n",
        "        self.classifier = torch.nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, sep_positions):\n",
        "        output = self.encoder[0].auto_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        token_embeddings = output.last_hidden_state\n",
        "        preds = []\n",
        "        for i in range(input_ids.shape[0]):\n",
        "            sep_pos = sep_positions[i]\n",
        "            if len(sep_pos) == 0:\n",
        "                continue\n",
        "            sentence_embs = token_embeddings[i, sep_pos, :].float()  # ensure float32\n",
        "            logits = self.classifier(sentence_embs).squeeze(-1)\n",
        "            preds.append(logits)\n",
        "        return preds\n",
        "\n",
        "model = MultiSentenceClassifier(MODEL_NAME).to(DEVICE)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# -----------------------\n",
        "# INFERENCE\n",
        "# -----------------------\n",
        "\n",
        "\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for item in tqdm(grouped_data):\n",
        "        question = item[\"question\"]\n",
        "        sentences = item[\"sentences\"]\n",
        "        true_labels = item[\"labels\"]\n",
        "\n",
        "        text = question + \" </s> \" + \" </s> \".join(sentences)\n",
        "        encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
        "        input_ids = encoding[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = encoding[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "        sent_token_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
        "        sep_positions = (input_ids[0] == sent_token_id).nonzero(as_tuple=True)[0]\n",
        "        if len(sep_positions) == 0:\n",
        "            sep_positions = torch.tensor([1]).to(DEVICE)\n",
        "\n",
        "        sep_positions = sep_positions.unsqueeze(0)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask, [sep_positions])\n",
        "        if outputs:\n",
        "            probs = torch.sigmoid(outputs[0]).cpu().numpy().reshape(-1)\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            # truncate to shortest length (safety check)\n",
        "            min_len = min(len(probs), len(true_labels))\n",
        "            probs = probs[:min_len]\n",
        "            preds = preds[:min_len]\n",
        "            labels = true_labels[:min_len]\n",
        "\n",
        "            # accumulate\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_targets.extend(labels)\n",
        "\n",
        "            # Optional: print per sentence\n",
        "            for i, (sent, prob, pred, label) in enumerate(zip(sentences[:min_len], probs, preds, labels)):\n",
        "                print(f\"Q: {question}\")\n",
        "                print(f\"SENT {i+1}: {sent}\")\n",
        "                #print(f\" â†’ Predicted: {pred}, Prob: {prob:.3f}, True: {label}\\n\")\n",
        "                print(f\" â†’ Predicted: {pred}, True: {label}\\n\")\n",
        "\n",
        "# -----------------------\n",
        "# GLOBAL METRICS\n",
        "# -----------------------\n",
        "print(\"\\nOverall Evaluation on Test Set:\")\n",
        "print(classification_report(all_targets, all_preds, digits=3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Raw metrics\n",
        "precision, recall, f1, support = precision_recall_fscore_support(all_targets, all_preds, average='binary', pos_label=1)\n",
        "\n",
        "print(\"\\nBinary-Averaged Metrics (positive class = 1):\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")\n",
        "# print(f\"Support:   {support}\")"
      ],
      "metadata": {
        "id": "MUkFWBIuGZVm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# CREATE EXPORTABLE RESULTS\n",
        "# -----------------------\n",
        "\n",
        "rows = []\n",
        "\n",
        "for case_id, item in tqdm(zip(df_test[\"case_id\"].unique(), grouped_data), total=len(grouped_data), desc=\"Generating report\"):\n",
        "    question = item[\"question\"]\n",
        "    labels = item[\"labels\"]\n",
        "    sentences = item[\"sentences\"]\n",
        "\n",
        "    # Rerun encoding for the item\n",
        "    text = question + \" </s> \" + \" </s> \".join(sentences)\n",
        "    encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
        "    input_ids = encoding[\"input_ids\"].to(DEVICE)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "    sent_token_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
        "    sep_positions = (input_ids[0] == sent_token_id).nonzero(as_tuple=True)[0]\n",
        "    if len(sep_positions) == 0:\n",
        "        sep_positions = torch.tensor([1]).to(DEVICE)\n",
        "    sep_positions = sep_positions.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask, [sep_positions])\n",
        "        probs = torch.sigmoid(outputs[0]).cpu().numpy().reshape(-1)\n",
        "        preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    min_len = min(len(preds), len(labels))\n",
        "    cited_ids = [str(i) for i, p in enumerate(preds[:min_len]) if p == 1]\n",
        "    gold_ids = [str(i) for i, l in enumerate(labels[:min_len]) if l == 1]\n",
        "\n",
        "    rows.append({\n",
        "        \"case_id\": case_id,\n",
        "        \"question\": question,\n",
        "        \"cited_sentence_ids\": \", \".join(cited_ids),\n",
        "        \"gold_essential_sentence_ids\": \", \".join(gold_ids)\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "df_out = pd.DataFrame(rows)\n",
        "\n",
        "# Save to Excel\n",
        "output_path = \"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/prediction_outputs/jina_citation_results_fine_tuned_patient_narrative.xlsx\"\n",
        "df_out.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"\\nSaved output to: {output_path}\")"
      ],
      "metadata": {
        "id": "dbCpJn940ph8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG\n",
        "# -----------------------\n",
        "PREDICTION_FILE = \"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/prediction_outputs/jina_citation_results_fine_tuned_patient_narrative.xlsx\"\n",
        "\n",
        "# -----------------------\n",
        "# LOAD\n",
        "# -----------------------\n",
        "df = pd.read_excel(PREDICTION_FILE)\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    gold_ids = set(map(int, str(row[\"gold_essential_sentence_ids\"]).split(\",\"))) if pd.notna(row[\"gold_essential_sentence_ids\"]) else set()\n",
        "    pred_ids = set(map(int, str(row[\"cited_sentence_ids\"]).split(\",\"))) if pd.notna(row[\"cited_sentence_ids\"]) else set()\n",
        "\n",
        "    max_id = max(gold_ids.union(pred_ids)) if gold_ids or pred_ids else -1\n",
        "\n",
        "    for i in range(max_id + 1):\n",
        "        y_true.append(1 if i in gold_ids else 0)\n",
        "        y_pred.append(1 if i in pred_ids else 0)\n",
        "\n",
        "# -----------------------\n",
        "# METRICS\n",
        "# -----------------------\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", pos_label=1)\n",
        "\n",
        "print(\"Evaluation Results of fine tuned model on dev with patient narrative:\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")"
      ],
      "metadata": {
        "id": "DT8sjkD55Wzk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Clinician question"
      ],
      "metadata": {
        "id": "QhiwBDf--Q5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG\n",
        "# -----------------------\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/fine_tuned_jina_v3_multisent.pt\"\n",
        "MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MAX_LENGTH = 4096\n",
        "\n",
        "# -----------------------\n",
        "# LOAD TEST DATA\n",
        "# -----------------------\n",
        "df_test = pd.read_excel(\"/content/gdrive/MyDrive/dataset_excel_bionlp/merged_notes_cases.xlsx\")\n",
        "\n",
        "question_column = 'clinician_question'\n",
        "# question_column = 'patient_narrative'\n",
        "df_test = df_test.rename(columns={question_column: 'question_generated'})\n",
        "\n",
        "\n",
        "df_test[\"ref_excerpt\"] = df_test[\"ref_excerpt\"].astype(str)\n",
        "df_test[\"binary_relevance\"] = df_test[\"relevance\"].apply(lambda x: 1 if x.strip().lower() == \"essential\" else 0)\n",
        "\n",
        "grouped_data = []\n",
        "for case_id, group in df_test.groupby(\"case_id\"):\n",
        "    question = group[\"question_generated\"].iloc[0]\n",
        "    sentences = group[\"ref_excerpt\"].tolist()\n",
        "    labels = group[\"binary_relevance\"].tolist()\n",
        "    grouped_data.append({\n",
        "        \"question\": question,\n",
        "        \"sentences\": [s.strip() for s in sentences],\n",
        "        \"labels\": labels\n",
        "    })\n",
        "\n",
        "# -----------------------\n",
        "# TOKENIZER AND MODEL\n",
        "# -----------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "class MultiSentenceClassifier(torch.nn.Module):\n",
        "    def __init__(self, base_model_name):\n",
        "        super().__init__()\n",
        "        self.encoder = SentenceTransformer(\n",
        "            base_model_name,\n",
        "            trust_remote_code=True,\n",
        "            model_kwargs={\"default_task\": \"classification\", \"use_flash_attn\": True}\n",
        "        )\n",
        "        hidden_size = self.encoder.get_sentence_embedding_dimension()\n",
        "        self.classifier = torch.nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, sep_positions):\n",
        "        output = self.encoder[0].auto_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        token_embeddings = output.last_hidden_state\n",
        "        preds = []\n",
        "        for i in range(input_ids.shape[0]):\n",
        "            sep_pos = sep_positions[i]\n",
        "            if len(sep_pos) == 0:\n",
        "                continue\n",
        "            sentence_embs = token_embeddings[i, sep_pos, :].float()  # ensure float32\n",
        "            logits = self.classifier(sentence_embs).squeeze(-1)\n",
        "            preds.append(logits)\n",
        "        return preds\n",
        "\n",
        "model = MultiSentenceClassifier(MODEL_NAME).to(DEVICE)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# -----------------------\n",
        "# INFERENCE\n",
        "# -----------------------\n",
        "\n",
        "\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for item in tqdm(grouped_data):\n",
        "        question = item[\"question\"]\n",
        "        sentences = item[\"sentences\"]\n",
        "        true_labels = item[\"labels\"]\n",
        "\n",
        "        text = question + \" </s> \" + \" </s> \".join(sentences)\n",
        "        encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
        "        input_ids = encoding[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = encoding[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "        sent_token_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
        "        sep_positions = (input_ids[0] == sent_token_id).nonzero(as_tuple=True)[0]\n",
        "        if len(sep_positions) == 0:\n",
        "            sep_positions = torch.tensor([1]).to(DEVICE)\n",
        "\n",
        "        sep_positions = sep_positions.unsqueeze(0)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask, [sep_positions])\n",
        "        if outputs:\n",
        "            probs = torch.sigmoid(outputs[0]).cpu().numpy().reshape(-1)\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            # truncate to shortest length (safety check)\n",
        "            min_len = min(len(probs), len(true_labels))\n",
        "            probs = probs[:min_len]\n",
        "            preds = preds[:min_len]\n",
        "            labels = true_labels[:min_len]\n",
        "\n",
        "            # accumulate\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_targets.extend(labels)\n",
        "\n",
        "            # Optional: print per sentence\n",
        "            for i, (sent, prob, pred, label) in enumerate(zip(sentences[:min_len], probs, preds, labels)):\n",
        "                print(f\"Q: {question}\")\n",
        "                print(f\"SENT {i+1}: {sent}\")\n",
        "                #print(f\" â†’ Predicted: {pred}, Prob: {prob:.3f}, True: {label}\\n\")\n",
        "                print(f\" â†’ Predicted: {pred}, True: {label}\\n\")\n",
        "\n",
        "# -----------------------\n",
        "# GLOBAL METRICS\n",
        "# -----------------------\n",
        "print(\"\\nOverall Evaluation on Test Set:\")\n",
        "print(classification_report(all_targets, all_preds, digits=3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Raw metrics\n",
        "precision, recall, f1, support = precision_recall_fscore_support(all_targets, all_preds, average='binary', pos_label=1)\n",
        "\n",
        "print(\"\\nBinary-Averaged Metrics\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")\n",
        "print(f\"Support:   {support}\")"
      ],
      "metadata": {
        "id": "3Hc3HjcX-Pk4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# CREATE EXPORTABLE RESULTS\n",
        "# -----------------------\n",
        "\n",
        "rows = []\n",
        "\n",
        "for case_id, item in tqdm(zip(df_test[\"case_id\"].unique(), grouped_data), total=len(grouped_data), desc=\"Generating report\"):\n",
        "    question = item[\"question\"]\n",
        "    labels = item[\"labels\"]\n",
        "    sentences = item[\"sentences\"]\n",
        "\n",
        "    # Rerun encoding for the item\n",
        "    text = question + \" </s> \" + \" </s> \".join(sentences)\n",
        "    encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
        "    input_ids = encoding[\"input_ids\"].to(DEVICE)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "    sent_token_id = tokenizer.convert_tokens_to_ids(\"</s>\")\n",
        "    sep_positions = (input_ids[0] == sent_token_id).nonzero(as_tuple=True)[0]\n",
        "    if len(sep_positions) == 0:\n",
        "        sep_positions = torch.tensor([1]).to(DEVICE)\n",
        "    sep_positions = sep_positions.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask, [sep_positions])\n",
        "        probs = torch.sigmoid(outputs[0]).cpu().numpy().reshape(-1)\n",
        "        preds = (probs > 0.5).astype(int)\n",
        "\n",
        "    min_len = min(len(preds), len(labels))\n",
        "    cited_ids = [str(i) for i, p in enumerate(preds[:min_len]) if p == 1]\n",
        "    gold_ids = [str(i) for i, l in enumerate(labels[:min_len]) if l == 1]\n",
        "\n",
        "    rows.append({\n",
        "        \"case_id\": case_id,\n",
        "        \"question\": question,\n",
        "        \"cited_sentence_ids\": \", \".join(cited_ids),\n",
        "        \"gold_essential_sentence_ids\": \", \".join(gold_ids)\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "df_out = pd.DataFrame(rows)\n",
        "\n",
        "# Save to Excel\n",
        "output_path = \"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/prediction_outputs/jina_citation_results_fine_tuned_clinician_question.xlsx\"\n",
        "df_out.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"\\nSaved output to: {output_path}\")"
      ],
      "metadata": {
        "id": "wA6tPe1T5_6V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG\n",
        "# -----------------------\n",
        "PREDICTION_FILE = \"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/prediction_outputs/jina_citation_results_fine_tuned_clinician_question.xlsx\"\n",
        "\n",
        "# -----------------------\n",
        "# LOAD\n",
        "# -----------------------\n",
        "df = pd.read_excel(PREDICTION_FILE)\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    gold_ids = set(map(int, str(row[\"gold_essential_sentence_ids\"]).split(\",\"))) if pd.notna(row[\"gold_essential_sentence_ids\"]) else set()\n",
        "    pred_ids = set(map(int, str(row[\"cited_sentence_ids\"]).split(\",\"))) if pd.notna(row[\"cited_sentence_ids\"]) else set()\n",
        "\n",
        "    max_id = max(gold_ids.union(pred_ids)) if gold_ids or pred_ids else -1\n",
        "\n",
        "    for i in range(max_id + 1):\n",
        "        y_true.append(1 if i in gold_ids else 0)\n",
        "        y_pred.append(1 if i in pred_ids else 0)\n",
        "\n",
        "# -----------------------\n",
        "# METRICS\n",
        "# -----------------------\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", pos_label=1)\n",
        "\n",
        "print(\"Evaluation Results of fine tuned model on dev with clinician question:\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")"
      ],
      "metadata": {
        "id": "ZJ1Ip7Ri4Tvc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Untuned Model"
      ],
      "metadata": {
        "id": "l-n9-8cizh32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Patient narrative"
      ],
      "metadata": {
        "id": "CY77Z5_N1853"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load pretrained model\n",
        "MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SentenceTransformer(MODEL_NAME, trust_remote_code=True).to(DEVICE)\n",
        "\n",
        "# Load test data\n",
        "df_test = pd.read_excel(\"/content/gdrive/MyDrive/dataset_excel_bionlp/merged_notes_cases.xlsx\")\n",
        "# question_column = 'clinician_question'\n",
        "question_column = 'patient_narrative'\n",
        "df_test = df_test.rename(columns={question_column: 'question_generated'})\n",
        "df_test[\"ref_excerpt\"] = df_test[\"ref_excerpt\"].astype(str)\n",
        "df_test[\"binary_relevance\"] = df_test[\"relevance\"].apply(lambda x: 1 if x.strip().lower() == \"essential\" else 0)\n",
        "\n",
        "# Group test cases\n",
        "grouped_data = []\n",
        "for case_id, group in df_test.groupby(\"case_id\"):\n",
        "    question = group[\"question_generated\"].iloc[0]\n",
        "    sentences = group[\"ref_excerpt\"].tolist()\n",
        "    labels = group[\"binary_relevance\"].tolist()\n",
        "    grouped_data.append({\n",
        "        \"question\": question,\n",
        "        \"sentences\": [s.strip() for s in sentences],\n",
        "        \"labels\": labels\n",
        "    })\n",
        "\n",
        "# Inference\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "for item in tqdm(grouped_data):\n",
        "    question = item[\"question\"]\n",
        "    sentences = item[\"sentences\"]\n",
        "    labels = item[\"labels\"]\n",
        "\n",
        "    # Encode question and sentences\n",
        "    # q_emb = model.encode(question, convert_to_tensor=True, task=\"classification\")\n",
        "    # sent_embs = model.encode(sentences, convert_to_tensor=True, task=\"classification\")\n",
        "    q_emb = model.encode(question, convert_to_tensor=True)\n",
        "    sent_embs = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "    # Cosine similarity\n",
        "    sims = util.cos_sim(q_emb, sent_embs)[0]  # shape: [#sentences]\n",
        "\n",
        "    # Threshold (you may want to tune this threshold based on val set)\n",
        "    threshold = 0.5\n",
        "    preds = (sims > threshold).int().tolist()\n",
        "\n",
        "    all_preds.extend(preds)\n",
        "    all_targets.extend(labels)\n",
        "\n",
        "    # Optional: print per sample\n",
        "    for i, (sent, pred, label) in enumerate(zip(sentences, preds, labels)):\n",
        "        print(f\"Q: {question}\")\n",
        "        print(f\"SENT {i+1}: {sent}\")\n",
        "        print(f\" â†’ Predicted: {pred}, True: {label}\\n\")\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nBaseline (untuned) model evaluation:\")\n",
        "print(classification_report(all_targets, all_preds, digits=3))"
      ],
      "metadata": {
        "id": "7DMnQ6mKzdE_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "# CREATE EXPORTABLE RESULTS\n",
        "# -----------------------\n",
        "\n",
        "results = []\n",
        "\n",
        "for case_id, item in zip(df_test[\"case_id\"].unique(), tqdm(grouped_data, desc=\"Running inference\", total=len(grouped_data))):\n",
        "    question = item[\"question\"]\n",
        "    sentences = item[\"sentences\"]\n",
        "    labels = item[\"labels\"]\n",
        "\n",
        "    # Encode question and sentences\n",
        "    q_emb = model.encode(question, convert_to_tensor=True)\n",
        "    sent_embs = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "    # Cosine similarity\n",
        "    sims = util.cos_sim(q_emb, sent_embs)[0]\n",
        "    threshold = 0.5\n",
        "    preds = (sims > threshold).int().tolist()\n",
        "\n",
        "    # Record sentence IDs (indices) that were predicted or truly essential\n",
        "    cited_ids = [str(i) for i, p in enumerate(preds) if p == 1]\n",
        "    gold_ids = [str(i) for i, g in enumerate(labels) if g == 1]\n",
        "\n",
        "    results.append({\n",
        "        \"case_id\": case_id,\n",
        "        \"question\": question,\n",
        "        \"cited_sentence_ids\": \",\".join(cited_ids),\n",
        "        \"gold_essential_sentence_ids\": \",\".join(gold_ids),\n",
        "    })\n",
        "\n",
        "# Save to Excel\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_excel(\"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/prediction_outputs/jina_citation_results_untuned_base_patient_narrative.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "DJ_-kv9B4Y8M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# -----------------------\n",
        "# CONFIG\n",
        "# -----------------------\n",
        "PREDICTION_FILE = \"/content/gdrive/MyDrive/qlora_outputs/05-05_BCEWithLogitsLoss_5_epochs/prediction_outputs/jina_citation_results_untuned_base_patient_narrative.xlsx\"\n",
        "\n",
        "# -----------------------\n",
        "# LOAD\n",
        "# -----------------------\n",
        "df = pd.read_excel(PREDICTION_FILE)\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    gold_ids = set(map(int, str(row[\"gold_essential_sentence_ids\"]).split(\",\"))) if pd.notna(row[\"gold_essential_sentence_ids\"]) else set()\n",
        "    pred_ids = set(map(int, str(row[\"cited_sentence_ids\"]).split(\",\"))) if pd.notna(row[\"cited_sentence_ids\"]) else set()\n",
        "\n",
        "    max_id = max(gold_ids.union(pred_ids)) if gold_ids or pred_ids else -1\n",
        "\n",
        "    for i in range(max_id + 1):\n",
        "        y_true.append(1 if i in gold_ids else 0)\n",
        "        y_pred.append(1 if i in pred_ids else 0)\n",
        "\n",
        "# -----------------------\n",
        "# METRICS\n",
        "# -----------------------\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", pos_label=1)\n",
        "\n",
        "print(\"Evaluation Results of fine tuned model on dev with patient narrative question:\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")"
      ],
      "metadata": {
        "id": "m4j_n0t24ZC1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Clinician question"
      ],
      "metadata": {
        "id": "7hqpaCH62AuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load pretrained model\n",
        "MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SentenceTransformer(MODEL_NAME, trust_remote_code=True).to(DEVICE)\n",
        "\n",
        "# Load test data\n",
        "df_test = pd.read_excel(\"/content/gdrive/MyDrive/dataset_excel_bionlp/merged_notes_cases.xlsx\")\n",
        "question_column = 'clinician_question'\n",
        "# question_column = 'patient_narrative'\n",
        "df_test = df_test.rename(columns={question_column: 'question_generated'})\n",
        "df_test[\"ref_excerpt\"] = df_test[\"ref_excerpt\"].astype(str)\n",
        "df_test[\"binary_relevance\"] = df_test[\"relevance\"].apply(lambda x: 1 if x.strip().lower() == \"essential\" else 0)\n",
        "\n",
        "# Group test cases\n",
        "grouped_data = []\n",
        "for case_id, group in df_test.groupby(\"case_id\"):\n",
        "    question = group[\"question_generated\"].iloc[0]\n",
        "    sentences = group[\"ref_excerpt\"].tolist()\n",
        "    labels = group[\"binary_relevance\"].tolist()\n",
        "    grouped_data.append({\n",
        "        \"question\": question,\n",
        "        \"sentences\": [s.strip() for s in sentences],\n",
        "        \"labels\": labels\n",
        "    })\n",
        "\n",
        "# Inference\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "for item in tqdm(grouped_data):\n",
        "    question = item[\"question\"]\n",
        "    sentences = item[\"sentences\"]\n",
        "    labels = item[\"labels\"]\n",
        "\n",
        "    # Encode question and sentences\n",
        "    q_emb = model.encode(question, convert_to_tensor=True)\n",
        "    sent_embs = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "    # Cosine similarity\n",
        "    sims = util.cos_sim(q_emb, sent_embs)[0]  # shape: [#sentences]\n",
        "\n",
        "    # Threshold (you may want to tune this threshold based on val set)\n",
        "    threshold = 0.5\n",
        "    preds = (sims > threshold).int().tolist()\n",
        "\n",
        "    all_preds.extend(preds)\n",
        "    all_targets.extend(labels)\n",
        "\n",
        "    # Optional: print per sample\n",
        "    for i, (sent, pred, label) in enumerate(zip(sentences, preds, labels)):\n",
        "        print(f\"Q: {question}\")\n",
        "        print(f\"SENT {i+1}: {sent}\")\n",
        "        print(f\" â†’ Predicted: {pred}, True: {label}\\n\")\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nBaseline (untuned) model evaluation:\")\n",
        "print(classification_report(all_targets, all_preds, digits=3))"
      ],
      "metadata": {
        "id": "i7LAHd0v2BxO"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}